perceptrons
	Effectively perceptrons exist to transform a real-valued vector of m elements
	to a single output f.

	Weight:
		Each perceptron has an associated weight which is used to determine the strength
		of connection it has to other perceptrons downstream. A bare network can be initialized
		with weights zero or close to zero, and through the process of backpropagation these
		weights will be updated accordingly

	Bias:
		The bias is simply an offset away from the origin, which allows you to shift
		the activation left or right, which may be necessary for proper learning, the
		bias allows you to fit the activiaton function to the data better

	A network with a single layer can classify data that is linearly separable, for non-linear
	classification you require multiple layers. 

	Activation functions:
		Your choice of activiation function is important especially for networks considering 
		of many layers, as during the process of back-propagation the possibility of losing
		your gradient becomes very real. Like in the case of the sigmoid activiation function
		the gradiant will just become smaller and smaller until it practically disappears

	Forward propagation:
		The activation is used to determine the weighted sum of all of the perceptrons inputs
		plus a bias term. The outputs of this layer determine the inputs of the following layers

	Back propagation:
		Back propagation aims to minimise the loss function by adjusting weights and biases
		accordingly. The loss function is used gague the difference between the output and
		the expected output

		Parameters:
			Learning rate epsilon determines how fast the weights and biases can be adjusted, or
			really it determines how large of an impact a single gradient can have

		The loss function is not a vector it is a single value, the loss function considers the
		network as a whole.

		https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications

		How do you choose your loss function? Your loss function has to be re-computed every time the
		desired output changes?

		You compute dC/dw and dC/db to see what effect a change in weight and bias selection has on the
		cost, but something to consider is the composite nature of this problem, if you change a given
		weight and/or bias in layer L-1, then a set of activations in L will subsequently change as well

		You have a cost function that is differentiable and can be written as an average over each individual
		training samples cost, and the cost function can be written as a massive composite chain of outputs
		from the previous layers in the network. The expected output ŷ is known and the number of training
		samples is also known

		overall the cost functions needs to be written as an average over all samples because that allows you
		to gague the cost of the network as a whole

		Logically it follows that if you can minimise the cost of individual samples that will lead the
		overall cost of the network to decrease as well

		The cost function can be thought of as a massive chain of composite functions from each preceding
		layers weights and biases, you differentiate using the chain rule. It also follows that layer L-1
		will have less compositions compared to layer L

		The logic is you want to descend down the cost function:
			C = (y - a)^2
			z = aW + b
			a = σ(z)

			dC/dw = dC/da dz/dw d z

			dC/da = 2(y - a)
			dz/dw = a
			da/dz = σ'(z)

			dC/dw = 2(y - a) * a * σ'(z)

		? Back propagation, compute dC/dw and dC/db on layer L, calculate for w1,w2,w3,...

	Ideas:
		A model that dynamically adjusts the learning rate and its choice of activation functions
		depending how efficiently it is learning alongside the state of the network
